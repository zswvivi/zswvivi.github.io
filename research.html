<!DOCTYPE html>
<html lang="en">

<head>
  <!-- Metadata for the Webpage -->
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Shiwei Zhang, Ph.D.</title>

  <!-- Favicons -- We recommend this site for generating favicons: https://www.favicon-generator.org/ -->
  <link rel="apple-touch-icon" sizes="57x57" href="favicons/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="favicons/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="favicons/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="favicons/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="favicons/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="favicons/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="favicons/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="favicons/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="favicons/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192" href="favicons/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="favicons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="favicons/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="favicons/favicon-16x16.png">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="favicons/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">

  <!-- Bootstrap CSS files-->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu" crossorigin="anonymous">

  <!-- jQuery UI CSS (optional) -->
  <link rel="stylesheet" href="https://ajax.googleapis.com/ajax/libs/jqueryui/1.12.1/themes/smoothness/jquery-ui.css">

  <!-- Google web fonts -->
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300;0,400;0,600;1,400&display=swap" rel="stylesheet">

  <!-- Font Awesome Web Icons -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">

  <!-- Academicons Courtesy of https://jpswalsh.github.io/academicons/ -->
  <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">

  <!-- Local styles -->
  <link rel="stylesheet" href="css/main.css">

</head>

<body>

  <!-- navbar include -->
  <div id="navbar-include"></div>

  <div class="spacer-div-3 hidden-xs hidden-xs"></div>

  <!-- Main content    -->
  <div id="main-container" class="container">

    <div class="row">
      <div class="col-sm-12">
        <h1>Research</h1>
        <p><strong>My research at RMIT: </strong> During my time at RMIT, I concentrated on utilizing neural models to analyze user-generated text, with a particular emphasis on tasks such as sentiment analysis, irony detection, and answering product-related questions. Through the process of tackling these complex issues, I gained expertise in adapting deep learning models to address specific problems and leveraging various resources and transfer learning techniques to enhance the models' effectiveness and interoperability.</p>
        <p><strong>My research at Tencent Jarvis lab: </strong> My primary focus in research revolves around enhancing medical NLP tasks that are integral to our AI-powered healthcare applications. These tasks encompass symptom detection, medical diagnosis via EHR, medical word embeddings, medical question answering, and medical generative models. </p>
        <p><strong>My current research interests: </strong> The scaling law predicts that as computation resources increase, AI systems' capabilities will also increase [1]. AI performance in many tasks is on par with or even surpasses human-level ability. As AI continues to advance, it has the potential to impact our lives and society in numerous ways. Leveraging large language models (LLMs) or other foundation models may become the predominant machine learning approach for solving problems in various domains. Therefore, it is crucial to conduct research on AI safety, reliability, and interpretability to ensure that these systems are robustly trustworthy and reliable. At present, my research encompasses researching various aspects of AI systems such as fine-tuning models, steerable text generation, and explainable AI:</p>
        <!-- List of Research interests -->
        <ul class="push-down-1 list-unstyled">
          <li><strong>1. Multi-task fine-tuning</strong>&mdash; AI systems are often trained in two stages: pre-training and fine-tuning. The fine-tuning methods for LLMs are more likely to be used to align AI systems with human values and intentions instead of improving performance, like reinforcement learning from human feedback (RLHF)[2] and reinforcement learning from AI feedback (RLAIF)[3]. These methods basically aim to update the model's pre-trained conditional probability of language towards human intent or value. I am interested in fine-tuning LLMs using resources from interconnected tasks, such as medicine-related tasks. This approach is expected to improve the reliability of LLMs in specific domains by transferring or sharing in-domain knowledge across related tasks, ultimately increasing the conditional probability of correct knowledge.</li>
          <li><strong>2. Steerable text generation</strong>&mdash; As AI systems become more capable, the challenge of directing them to generate content that aligns with our rules becomes crucial and fascinating. Several tasks, including named entity recognition (NER), relationship extraction, classification, and relevance-based tasks, demand well-structured outputs. It is essential to design decoding methods or impose specific constraints to ensure that the generated text meets the task requirements and falls within the answer scope. Most importantly, controllable content generation is crucial to prevent AI systems from producing harmful content.</li>
          <li><strong>3. Explainable AI</strong>&mdash; The LLMs' capabilities enable the model to predict answers with explanations by utilizing techniques such as chain-of-thought[4]. I am passionate about exploring approaches for interpreting AI systems, which are important for deploying AI systems for high-stake tasks, such as medical diagnosis and self-driving. </li>
        </ul>

        <!-- Publication -->
        <h3 class="push-down-4"><span>Publications</span></h3>
        <h5><span>2022</span></h5>
        <ul class="publications">
          <li>Medical Symptom Detection in Intelligent Pre-Consultation using Bi-directional Hard-Negative Noise Contrastive Estimation. <b>Shiwei Zhang</b>, Jichao Sun, Yu Huang, Xueqi Ding, and Yefeng Zheng. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), 2022. <a href="/img/Medical_Symptom_Detection.pdf"> paper</a> / <a href="https://github.com/zswvivi/bihardnce">code</a></li><br>
          <li>Prompt Combines Paraphrase: Teaching Pre-trained Models to Understand Rare Biomedical Words. Haochun Wang, Chi Liu, Nuwa Xi, Sendong Zhao, Meizhi Ju, <b>Shiwei Zhang</b>, Ziheng Zhang, Yefeng Zheng, Bing Qin, and Ting Liu. In Proceedings of the 29th International Conference on Computational Linguistics (COLING), 2022. <a href="https://arxiv.org/pdf/2209.06453"> paper </a></li><br>
        </ul>

        <h5><span>2021</span></h5>
        <ul class="publications">
          <li>Does QA-based Intermediate Training Help Fine-tuning Language Models for Text Classification?. <b>Shiwei Zhang</b>, Xiuzhen Zhang. In Proceedings of the 19th Annual Workshop of the Australasian Language Technology Association (ALTA), 2021. <a href="https://arxiv.org/pdf/2112.15051"> paper </a></li><br>
        </ul>

        <h5><span>2020</span></h5>
        <ul class="publications">
          <li>Less is More: Rejecting Unreliable Reviews for Product Question Answering. <b>Shiwei Zhang</b>, Xiuzhen Zhang, Jey Han Lau, Jeffrey Chan, and Cecile Paris. In Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD), 2020. <a href="/img/pqa02.pdf">paper</a> / <a href="https://github.com/zswvivi/ecml_pqa">code</a> </li><br>
          <li>Evaluation of Cross Domain Text Summarization. Scanlon, Liam, <b>Shiwei Zhang</b>, Xiuzhen Zhang, and Mark Sanderson. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), 2020. <a href="http://marksanderson.org/publications/my_papers/SIGIR2020_Submission_Liam.pdf"> paper </a></li><br>
        </ul>

        <h5><span>2019</span></h5>
        <ul class="publications">
          <li>Discovering Relevant Reviews for Answering Product-related Queries. <b>Shiwei Zhang</b>, Jey Han Lau, Xiuzhen Zhang, Jeffrey Chan, and Cecile Paris. In Proceedings of the International Conference on Data Mining (ICDM), 2019. <a href="/img/pqa01.pdf">paper</a> / <a href="https://github.com/zswvivi/icdm_pqa">code</a></li><br>
          <li>Irony Detection via Sentiment-based Transfer Learning. <b>Shiwei Zhang</b>, Xiuzhen Zhang, Jeffrey Chan, and Paolo Rosso. Information Processing & Management, 2019. <b>Best Paper Award</b> <a href="/img/Irony_Detection.pdf">paper</a> </li><br>
        </ul>

        <h5><span>2017</span></h5>
        <ul class="publications">
          <li>Language-independent Twitter Classification using Character-based Convolutional Networks. <b>Shiwei Zhang</b>, Xiuzhen Zhang, and Jeffrey Chan. In Proceedings of the International Conference on Advanced Data Mining and Applications (ADMA), 2017. <a href="https://www.researchgate.net/profile/Shiwei-Zhang-7/publication/320378286_Language-Independent_Twitter_Classification_Using_Character-Based_Convolutional_Networks/links/59f68f8ca6fdcc075ec602bf/Language-Independent-Twitter-Classification-Using-Character-Based-Convolutional-Networks.pdf">paper</a> </li><br>
          <li>A Word-character Convolutional Neural Network for Language-agnostic Twitter Sentiment Analysis. <b>Shiwei Zhang</b>, Xiuzhen Zhang, and Jeffrey Chan. In Proceedings of the Australasian Document Computing Symposium (ADCS), 2017. <a href="https://www.researchgate.net/profile/Shiwei-Zhang-7/publication/321786948_A_Word-Character_Convolutional_Neural_Network_for_Language-Agnostic_Twitter_Sentiment_Analysis/links/5a4999410f7e9ba868ad86f0/A-Word-Character-Convolutional-Neural-Network-for-Language-Agnostic-Twitter-Sentiment-Analysis.pdf">paper</a> </li><br>
        </ul>
       
        <!-- Dissertation abstract -->
        <h3 class="push-down-3"><span>Dissertation</span></h3>
        <p>Title: <a href="/img/Dissertation.pdf">Mining User-generated Texts via Neural Classification</a> </p>
  
        <!-- References -->
        <h3 class="push-down-3"><span>References</span></h3>
        <p>[1] Kaplan, J., McCandlish, S., Henighan, T., Brown, T.B., Chess, B., Child, R., Gray, S., Radford, A., Wu, J. and Amodei, D., 2020. Scaling laws for neural language models.</p>
        <p>[2] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A. and Schulman, J., 2022. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35, pp.27730-27744.</p>
        <p>[3] Bai, Y., Kadavath, S., Kundu, S., Askell, A., Kernion, J., Jones, A., Chen, A., Goldie, A., Mirhoseini, A., McKinnon, C. and Chen, C., 2022. Constitutional AI: Harmlessness from AI Feedback.</p>
        <p>[4] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Le, Q. and Zhou, D., 2022. Chain of thought prompting elicits reasoning in large language models.</p>

      </div>
    </div>

  </div>

  <!-- Back-to-top button -->
  <a role="button" id="topper" data-toggle="tooltip" data-placement="top" title="Top" class="btn scroll-link" href="#top"><i class="fa fa-fw fa-2x fa-caret-up" aria-hidden="true"></i></a>

  <!-- footer include -->
  <div w3-include-html="footer.html"></div>

  <!-- jQuery -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

  <!-- Bootstrap JS Library -->
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd" crossorigin="anonymous"></script>

  <!-- html file include script | used for navbar and footer -->
  <script src="js/w3data.js"></script>
  <script>
    w3IncludeHTML()
  </script>

  <!-- Local scripts -->
  <script src="js/main.js"></script>

  <script>
    $(document).ready(function() {

      $("#navbar-include").load("navbar.html", function() {

        $("#home").removeClass("active");
        $("#research").addClass("active");

      });
    });
  </script>

</body>

</html>
